
== 1.9.4.9

This section lists the new features, enhancements and fixed issues for
the releases starting from 1.9.4.9 to 1.0.

* Added WAN Replication (synchronization of separate active clusters).
* Added Data Affinity (co-location of related entries) feature.
* Added EC2 Auto Discovery for your Hazelcast cluster running on Amazon
EC2 platform.
* Implemented Distributed CountDownLatch.
* Implemented Distributed Semaphore implementation.
* Hazelcast distribution now contains HTML and PDF documentation besides
Javadoc.
* Better TCP/IP and multicast join support. Handling more edge cases
like multiple nodes starting at the same time.
* Memcache protocol: Better integration between Java and Memcache
clients. Put from memcache, get from Java client.
* Monitoring Tool is removed from the project.
* Re-implementation of distributed queue:
** Configurable backup count and synchronous backup.
** Persistence support based on backing MapStore.
** Auto-recovery from backing MapStore on startup.
* Re-implementation of distributed list supporting index based
operations.
* Optimized `IMap.putAll` for much faster bulk writes.
* Added `IMap.getAll` for bulk reads which is calling
`MapLoader.loadAll` if necessary.
* Added `IMap.tryLockAndGet` and `IMap.putAndUnlock` methods.
* Added `IMap.putTransient` API for storing only in-memory.
* Added `IMap.addLocalEntryListener()` for listening locally owned entry
events.
* Added `IMap.flush()` for flushing the dirty entries into MapStore.
* Added `MapLoader.getAllKeys` API for auto-pre-populating the map when
cluster starts.
* Support for minimum initial cluster size to enable equally partitioned
start.
* Introduced graceful shutdown.
* Faster dead-member detection.
* Memcache interface support. Memcache clients written in any language
can access Hazelcast cluster.
* RESTful access support,
e.g.Â http://:5701/hazelcast/rest/maps/mymap/key1.
* Added split-brain (network partitioning) handling.
* Added LifecycleService API to restart, pause Hazelcast instances and
listen for the lifecycle events.
* Added asynchronous put and get support for IMap via `IMap.asyncPut()`
and `IMap.asyncGet()`.
* Added AtomicNumber API; distributed implementation of
`java.util.concurrent.atomic.AtomicLong`.
* Significant performance gain for multi-core servers. Higher CPU
utilization and lower latency.
* Reduced the cost of map entries by 50 percent.
* Better thread management. No more idle threads.
* Added queue statistics API and the queue statistics panel on the
Monitoring Tool.
* Monitoring Tool enhancements. More responsive and robust.
* Hazelcast distribution now contains `hazelcast-all-<version>.jar` to
simplify the JAR dependency.
* Sorted index optimization for map queries.
* Added Hazelcast Cluster Monitoring Tool.
* Added Partition API. Partition and key owner, migration listeners.
* Added `IMap.lockMap()` method.
* Added Multicast and TCP/IP join feature. Try multicast first, if not
found, try TCP/IP.
* Added `Hazelcast.getExecutorService(name)` API. You can have separate
named executor services. Do not let your big tasks blocking your small
ones.
* Added `Logging` API. Build your own logging. or simply use Log4j or
get logs as LogEvents.
* Added `MapStatistics` API. Get statistics for your Map operations and
entries.
* Hazelcast client now automatically updates the member list. There is
no need to pass the list to all members.
* Added the ability to start the cluster members evenly partitioned.
Hence, no migration.
* Added Java clients for accessing the cluster remotely.
* Added Distributed Query for maps. Both Criteria API and SQL are
supported.
* Added near cache feature for distributed maps.
* Added TTL (time-to-live) property for each individual map entry.
* Improved the put operation: `IMap.put(key,value, ttl, timeunit)`.
* Introduced the method `IMap.putIfAbsent(key,value, ttl, timeunit)`.
* Now, you can have multiple Hazelcast members on the same JVM.
Introduced `HazelcastInstance` API.
* Better API based configuration support.
* Smoother data migration enabling better response times during joins.
* Persistence via Loader/Store interface for distributed map.
* Added Socket level encryption feature. Both symmetric and asymmetric
encryption are supported.
* Added support for JMX.
* Added support for Hibernate second level cache provider.
* Added instance events for getting notified when a data structure
instance (map, queue, topic, etc.) is created or destroyed.
* Added eviction listener: `EntryListener.entryEvicted(EntryEvent)`.
* Hazelcast is now fully ``maven''ized.
* Added support for synchronous backups and configurable backup-count
for maps.
* Added eviction support: Timed eviction for queues. LRU, LFU and time
based eviction for maps.
* Added support for statistics/history for entries: create/update time,
number of hits, cost.
* Implemented MultiMap structure. Similar to `google-collections` and
`apache-common-collections`, but distributed and thread-safe.
* Now, you can `destroy()` the data structures when not needed anymore.
* Now, you can shutdown the local member using `Hazelcast.shutdown()`.
* Now, you can get the list of all data structure instances via
`Hazelcast.getInstances()`.
* Full implementation of `java.util.concurrent.BlockingQueue`. Now,
queues can have configurable capacity limits.
* Introduced Super Clients (a.k.a LiteMember): Members with no storage.
If `-Dhazelcast.super.client=true` JVM parameter is set, that JVM will
join the cluster as a `super client' which will not be a `data
partition' (no data on that node) but will have super fast access to the
cluster just like any regular member does.
* Added HTTP Session sharing support for Hazelcast Web Manager.
Different web applications can share the same sessions.
* Added the ability to separate clusters by creating groups.
* Added `java.util.logging` support.
* Added the support for adding, removing and updating events for queue,
map, set and list data structures.
* Introduced Distributed Topic for pub/sub messaging.
* Added integration with J2EE transactions via JCA complaint resource
adapter.
* Added `ExecutionCallback` interface for distributed tasks.
* Introduced cluster-wide unique ID generator.
* Implemented Transactional Distributed Queue, Map, Set and List.
* Implemented Distributed Executor Service.
* Added support for multi member executions.
* Implemented key based execution routing.
* Added task cancellation support.
* Implemented Session Clustering with Hazelcast Webapp Manager.
* Added full TCP/IP clustering support.
* Introduced distributed implementation of
`java.util.{Queue,Map,Set,List}`.
* Introduced distributed implementation of `java.util.concurrency.Lock`.
* Added support for retrieving cluster membership events.
* 1000+ commits 100+ bug fixes and several other enhancements.
